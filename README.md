# NumPy MLP for MNIST

This is a project to build a Multi-Layer Perceptron (MLP) neural network entirely from scratch using only NumPy, with the aim of classifying handwritten digits from the MNIST dataset.

## Project Goal

The primary aim of this project is to gain a deep, fundamental understanding of how neural networks operate. This involves implementing all core components – from forward and backward passes to activation functions, loss calculations, and optimizers – without relying on the high-level abstractions provided by deep learning frameworks like TensorFlow or PyTorch for the model's definition and training process.

## Results

On a set random seed of 20, the model achieved 96.30% test accuracy on the MNIST dataset, with an average test accuracy of 96.22% across 5 random seeds.
